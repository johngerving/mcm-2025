{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "f77cd5e8-39d7-48aa-bfc5-42b200e9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1ce8a39e-dae0-42cd-82c9-0cf1c6e5285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Bronze</th>\n",
       "      <th>Total</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Is_Host</th>\n",
       "      <th>Ex-Host</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Events</th>\n",
       "      <th>Events Difference</th>\n",
       "      <th>Team Size Diff</th>\n",
       "      <th>Rolling Mean Team Size</th>\n",
       "      <th>Rolling Dev Team Size</th>\n",
       "      <th>Rolling Mean Participated Events</th>\n",
       "      <th>Rolling Dev Participated Events</th>\n",
       "      <th>Normalized Team Size</th>\n",
       "      <th>Normalized Participated Events</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>97.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.60</td>\n",
       "      <td>21.73</td>\n",
       "      <td>9.80</td>\n",
       "      <td>8.23</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1908.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>110.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.60</td>\n",
       "      <td>22.61</td>\n",
       "      <td>8.80</td>\n",
       "      <td>9.07</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1920.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>156.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>23.27</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.64</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>16.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1924.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>126.00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>46.98</td>\n",
       "      <td>11.80</td>\n",
       "      <td>16.71</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1928.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>109.00</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>56.28</td>\n",
       "      <td>16.40</td>\n",
       "      <td>21.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>12.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1932.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>117.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-51.00</td>\n",
       "      <td>51.20</td>\n",
       "      <td>51.45</td>\n",
       "      <td>22.20</td>\n",
       "      <td>19.74</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>14.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1936.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>129.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>64.60</td>\n",
       "      <td>43.17</td>\n",
       "      <td>28.20</td>\n",
       "      <td>15.87</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>13.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1948.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>136.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>227.00</td>\n",
       "      <td>123.40</td>\n",
       "      <td>99.00</td>\n",
       "      <td>48.20</td>\n",
       "      <td>29.86</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>19.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1952.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>149.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>-121.00</td>\n",
       "      <td>136.40</td>\n",
       "      <td>100.89</td>\n",
       "      <td>55.80</td>\n",
       "      <td>31.71</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>29.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1956.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>151.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>125.60</td>\n",
       "      <td>108.62</td>\n",
       "      <td>54.20</td>\n",
       "      <td>32.89</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>30.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1960.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>150.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>139.40</td>\n",
       "      <td>100.19</td>\n",
       "      <td>59.00</td>\n",
       "      <td>30.11</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>30.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1964.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>163.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>155.40</td>\n",
       "      <td>91.99</td>\n",
       "      <td>68.40</td>\n",
       "      <td>26.27</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>41.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1968.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>172.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>122.80</td>\n",
       "      <td>48.98</td>\n",
       "      <td>60.20</td>\n",
       "      <td>18.93</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>33.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1972.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>195.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>112.60</td>\n",
       "      <td>40.17</td>\n",
       "      <td>57.20</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1976.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>198.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>60.80</td>\n",
       "      <td>10.73</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1984.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>221.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>124.80</td>\n",
       "      <td>16.15</td>\n",
       "      <td>64.00</td>\n",
       "      <td>10.58</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>35.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1988.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>237.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>122.00</td>\n",
       "      <td>11.73</td>\n",
       "      <td>59.00</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>54.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>257.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>-23.00</td>\n",
       "      <td>117.80</td>\n",
       "      <td>10.99</td>\n",
       "      <td>60.60</td>\n",
       "      <td>8.88</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>54.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1996.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>137.40</td>\n",
       "      <td>47.92</td>\n",
       "      <td>68.60</td>\n",
       "      <td>20.66</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>57.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>300.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>-56.00</td>\n",
       "      <td>149.20</td>\n",
       "      <td>45.46</td>\n",
       "      <td>78.20</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>38.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>301.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>162.00</td>\n",
       "      <td>42.32</td>\n",
       "      <td>81.40</td>\n",
       "      <td>20.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>35.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>302.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-34.00</td>\n",
       "      <td>164.20</td>\n",
       "      <td>40.76</td>\n",
       "      <td>85.00</td>\n",
       "      <td>15.36</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>42.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2012.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>302.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>171.60</td>\n",
       "      <td>30.84</td>\n",
       "      <td>84.60</td>\n",
       "      <td>15.93</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>26.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>306.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>173.80</td>\n",
       "      <td>35.31</td>\n",
       "      <td>80.20</td>\n",
       "      <td>12.62</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>72.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>339.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>-24.00</td>\n",
       "      <td>182.40</td>\n",
       "      <td>37.78</td>\n",
       "      <td>72.80</td>\n",
       "      <td>10.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>52.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2024.00</td>\n",
       "      <td>ARG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>329.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-54.00</td>\n",
       "      <td>177.40</td>\n",
       "      <td>39.93</td>\n",
       "      <td>63.80</td>\n",
       "      <td>14.55</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank        NOC  Gold  Silver  Bronze  Total    Year Country Code  \\\n",
       "92   0.00  Argentina  0.00    0.00    0.00   0.00 1900.00          ARG   \n",
       "93   0.00  Argentina  0.00    0.00    0.00   0.00 1908.00          ARG   \n",
       "94   0.00  Argentina  0.00    0.00    0.00   0.00 1920.00          ARG   \n",
       "95  16.00  Argentina  1.00    3.00    2.00   6.00 1924.00          ARG   \n",
       "96  12.00  Argentina  3.00    3.00    1.00   7.00 1928.00          ARG   \n",
       "97  12.00  Argentina  3.00    1.00    0.00   4.00 1932.00          ARG   \n",
       "98  14.00  Argentina  2.00    2.00    3.00   7.00 1936.00          ARG   \n",
       "99  13.00  Argentina  3.00    3.00    1.00   7.00 1948.00          ARG   \n",
       "100 19.00  Argentina  1.00    2.00    2.00   5.00 1952.00          ARG   \n",
       "101 29.00  Argentina  0.00    1.00    1.00   2.00 1956.00          ARG   \n",
       "102 30.00  Argentina  0.00    1.00    1.00   2.00 1960.00          ARG   \n",
       "103 30.00  Argentina  0.00    1.00    0.00   1.00 1964.00          ARG   \n",
       "104 41.00  Argentina  0.00    0.00    2.00   2.00 1968.00          ARG   \n",
       "105 33.00  Argentina  0.00    1.00    0.00   1.00 1972.00          ARG   \n",
       "106  0.00  Argentina  0.00    0.00    0.00   0.00 1976.00          ARG   \n",
       "107  0.00  Argentina  0.00    0.00    0.00   0.00 1984.00          ARG   \n",
       "108 35.00  Argentina  0.00    1.00    1.00   2.00 1988.00          ARG   \n",
       "109 54.00  Argentina  0.00    0.00    1.00   1.00 1992.00          ARG   \n",
       "110 54.00  Argentina  0.00    2.00    1.00   3.00 1996.00          ARG   \n",
       "111 57.00  Argentina  0.00    2.00    2.00   4.00 2000.00          ARG   \n",
       "112 38.00  Argentina  2.00    0.00    4.00   6.00 2004.00          ARG   \n",
       "113 35.00  Argentina  2.00    0.00    4.00   6.00 2008.00          ARG   \n",
       "114 42.00  Argentina  1.00    1.00    2.00   4.00 2012.00          ARG   \n",
       "115 26.00  Argentina  3.00    1.00    0.00   4.00 2016.00          ARG   \n",
       "116 72.00  Argentina  0.00    1.00    2.00   3.00 2020.00          ARG   \n",
       "117 52.00  Argentina  1.00    1.00    1.00   3.00 2024.00          ARG   \n",
       "\n",
       "     Is_Host  Ex-Host  ...  Total Events  Events Difference  Team Size Diff  \\\n",
       "92      0.00     0.00  ...         97.00              54.00            0.00   \n",
       "93      0.00     0.00  ...        110.00              34.00            0.00   \n",
       "94      0.00     0.00  ...        156.00              54.00            0.00   \n",
       "95      0.00     0.00  ...        126.00             -30.00          108.00   \n",
       "96      0.00     0.00  ...        109.00             -17.00          -11.00   \n",
       "97      0.00     0.00  ...        117.00               8.00          -51.00   \n",
       "98      0.00     0.00  ...        129.00              12.00           21.00   \n",
       "99      0.00     0.00  ...        136.00               7.00          227.00   \n",
       "100     0.00     0.00  ...        149.00              13.00         -121.00   \n",
       "101     0.00     0.00  ...        151.00               2.00         -130.00   \n",
       "102     0.00     0.00  ...        150.00              -1.00           72.00   \n",
       "103     0.00     0.00  ...        163.00              13.00           32.00   \n",
       "104     0.00     0.00  ...        172.00               9.00          -16.00   \n",
       "105     0.00     0.00  ...        195.00              23.00           -9.00   \n",
       "106     0.00     0.00  ...        198.00               3.00          -17.00   \n",
       "107     0.00     0.00  ...        221.00              18.00            9.00   \n",
       "108     0.00     0.00  ...        237.00              16.00           19.00   \n",
       "109     0.00     0.00  ...        257.00              20.00          -23.00   \n",
       "110     0.00     0.00  ...        271.00              14.00          110.00   \n",
       "111     0.00     0.00  ...        300.00              29.00          -56.00   \n",
       "112     0.00     0.00  ...        301.00               1.00           14.00   \n",
       "113     0.00     0.00  ...        302.00               1.00          -34.00   \n",
       "114     0.00     0.00  ...        302.00               0.00            3.00   \n",
       "115     0.00     0.00  ...        306.00               4.00           84.00   \n",
       "116     0.00     0.00  ...        339.00              33.00          -24.00   \n",
       "117     0.00     0.00  ...        329.00             -10.00          -54.00   \n",
       "\n",
       "     Rolling Mean Team Size  Rolling Dev Team Size  \\\n",
       "92                    19.60                  21.73   \n",
       "93                    18.60                  22.61   \n",
       "94                    17.80                  23.27   \n",
       "95                    30.00                  46.98   \n",
       "96                    42.00                  56.28   \n",
       "97                    51.20                  51.45   \n",
       "98                    64.60                  43.17   \n",
       "99                   123.40                  99.00   \n",
       "100                  136.40                 100.89   \n",
       "101                  125.60                 108.62   \n",
       "102                  139.40                 100.19   \n",
       "103                  155.40                  91.99   \n",
       "104                  122.80                  48.98   \n",
       "105                  112.60                  40.17   \n",
       "106                  125.00                  16.00   \n",
       "107                  124.80                  16.15   \n",
       "108                  122.00                  11.73   \n",
       "109                  117.80                  10.99   \n",
       "110                  137.40                  47.92   \n",
       "111                  149.20                  45.46   \n",
       "112                  162.00                  42.32   \n",
       "113                  164.20                  40.76   \n",
       "114                  171.60                  30.84   \n",
       "115                  173.80                  35.31   \n",
       "116                  182.40                  37.78   \n",
       "117                  177.40                  39.93   \n",
       "\n",
       "     Rolling Mean Participated Events  Rolling Dev Participated Events  \\\n",
       "92                               9.80                             8.23   \n",
       "93                               8.80                             9.07   \n",
       "94                               8.00                             9.64   \n",
       "95                              11.80                            16.71   \n",
       "96                              16.40                            21.09   \n",
       "97                              22.20                            19.74   \n",
       "98                              28.20                            15.87   \n",
       "99                              48.20                            29.86   \n",
       "100                             55.80                            31.71   \n",
       "101                             54.20                            32.89   \n",
       "102                             59.00                            30.11   \n",
       "103                             68.40                            26.27   \n",
       "104                             60.20                            18.93   \n",
       "105                             57.20                            16.65   \n",
       "106                             60.80                            10.73   \n",
       "107                             64.00                            10.58   \n",
       "108                             59.00                             7.87   \n",
       "109                             60.60                             8.88   \n",
       "110                             68.60                            20.66   \n",
       "111                             78.20                            21.00   \n",
       "112                             81.40                            20.66   \n",
       "113                             85.00                            15.36   \n",
       "114                             84.60                            15.93   \n",
       "115                             80.20                            12.62   \n",
       "116                             72.80                            10.18   \n",
       "117                             63.80                            14.55   \n",
       "\n",
       "     Normalized Team Size  Normalized Participated Events  Sex  \n",
       "92                  -0.86                           -1.07 1.00  \n",
       "93                  -0.78                           -0.86 1.00  \n",
       "94                  -0.72                           -0.73 1.00  \n",
       "95                   1.68                            1.63 1.00  \n",
       "96                   1.00                            1.12 1.00  \n",
       "97                  -0.08                            0.40 1.00  \n",
       "98                   0.08                            0.18 0.99  \n",
       "99                   1.73                            1.77 0.93  \n",
       "100                  0.37                            0.67 0.90  \n",
       "101                 -0.75                           -0.67 0.98  \n",
       "102                 -0.23                           -0.17 0.99  \n",
       "103                 -0.08                            0.37 0.93  \n",
       "104                  0.19                           -0.01 0.93  \n",
       "105                  0.26                            0.29 0.92  \n",
       "106                 -1.19                           -1.01 0.83  \n",
       "107                 -0.61                            0.57 0.85  \n",
       "108                  1.02                           -0.76 0.76  \n",
       "109                 -0.62                            0.83 0.74  \n",
       "110                  1.74                            1.62 0.69  \n",
       "111                  0.35                            0.94 0.68  \n",
       "112                  0.40                            0.22 0.69  \n",
       "113                 -0.47                           -0.91 0.61  \n",
       "114                 -0.77                           -1.17 0.70  \n",
       "115                  1.65                           -0.02 0.65  \n",
       "116                  0.68                           -1.16 0.68  \n",
       "117                 -0.59                           -1.57 0.75  \n",
       "\n",
       "[26 rows x 23 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/full_medal_data.csv')\n",
    "sex = pd.read_csv('data/summerOly_athletes.csv')[['NOC', 'Year', 'Sex']].sort_values(by=['NOC', 'Year']).reset_index(drop=True)\n",
    "sex = sex.groupby(['NOC', 'Year'])['Sex'].apply(lambda x: (x == 'M').mean()).reset_index()\n",
    "events = pd.read_csv('data/summerOly_programs.csv').loc[71].reset_index()[4:].rename(columns={'index': 'Year', 71: 'Events'}).astype({'Events': 'int32'})\n",
    "events['Year'] = events['Year'].str.replace('*', '')\n",
    "events['Difference'] = events['Events'].diff().fillna(0)\n",
    "events = events.astype({'Year': 'int32'}).reset_index(drop=True)\n",
    "\n",
    "for i in range(len(events)):\n",
    "    df.loc[df['Year'] == events.loc[i, 'Year'], 'Events Difference'] = events.loc[i, 'Difference']\n",
    "    \n",
    "\n",
    "df = df.sort_values(by=['Country Code', 'Year']).reset_index(drop=True)\n",
    "\n",
    "countries = df['Country Code'].unique()\n",
    "for country_name in countries:\n",
    "    country = df[df['Country Code'] == country_name]\n",
    "    diff = country[['Team Size']].diff().fillna(0)\n",
    "\n",
    "    df.loc[df['Country Code'] == country_name, 'Team Size Diff'] = diff.loc[:, 'Team Size']\n",
    "\n",
    "    df.loc[df['Country Code'] == country_name, 'Rolling Mean Team Size'] = df[['Team Size']].rolling(window=5, min_periods=1).mean().loc[:, 'Team Size']\n",
    "    df.loc[df['Country Code'] == country_name, 'Rolling Dev Team Size'] = df[['Team Size']].rolling(window=5, min_periods=1).std().loc[:, 'Team Size']\n",
    "    \n",
    "    df.loc[df['Country Code'] == country_name, 'Rolling Mean Participated Events'] = df[['Participated Events']].rolling(window=5, min_periods=1).mean().loc[:, 'Participated Events']\n",
    "    df.loc[df['Country Code'] == country_name, 'Rolling Dev Participated Events'] = df[['Participated Events']].rolling(window=5, min_periods=1).std().loc[:, 'Participated Events']\n",
    "\n",
    "\n",
    "df['Normalized Team Size'] = (df['Team Size'] - df['Rolling Mean Team Size']) / df['Rolling Dev Team Size']\n",
    "df['Normalized Participated Events'] = (df['Participated Events'] - df['Rolling Mean Participated Events']) / df['Rolling Dev Participated Events']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sex_country_yr = sex[(sex['NOC'] == df.loc[i,'Country Code']) & (sex['Year'] == df.loc[i,'Year'])]\n",
    "    if len(sex_country_yr) == 0:\n",
    "        continue\n",
    "    df.loc[i,'Sex'] = sex_country_yr.iloc[0, 2]\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.where(df['NOC'] == 'Argentina').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "11677c7d-9bd2-41cf-a5c0-b64d7491212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['Country Code'].unique()\n",
    "\n",
    "rows = []\n",
    "for country_name in countries:\n",
    "    country = df[df['Country Code'] == country_name][['Country Code', 'Year', 'Total', 'Team Size', 'Participated Events', 'Sex', 'Host Continent', 'Normalized Team Size', 'Normalized Participated Events', 'Ex-Host']]\n",
    "    \n",
    "    first_medal_yr = country[country['Total'] > 0]\n",
    "    if len(first_medal_yr) == 0:\n",
    "        continue\n",
    "\n",
    "    first_medal_yr = first_medal_yr.iloc[0,1]\n",
    "\n",
    "    first_medal = df[(df['Year'] == first_medal_yr) & (df['Country Code'] == country_name)]\n",
    "    no_medals = df[(df['Year'] < first_medal_yr) & (df['Country Code'] == country_name)]\n",
    "\n",
    "    rows.append([*first_medal.iloc[0].loc[['Team Size', 'Participated Events', 'Sex', 'Events Difference', 'Host Continent', 'Normalized Team Size', 'Normalized Participated Events']], 1])\n",
    "    for i in range(len(no_medals)):\n",
    "        rows.append([*no_medals.iloc[i].loc[['Team Size', 'Participated Events', 'Sex', 'Events Difference', 'Host Continent', 'Normalized Team Size', 'Normalized Participated Events']], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "c7606993-1a44-43d5-b5c6-3b36adec8d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x304993450>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_medals = pd.DataFrame(rows, columns=['Team Size', 'Participated Events', 'Sex', 'Events Difference', 'Host Continent', 'Normalized Team Size', 'Normalized Participated Events' 'First Medal'])\n",
    "plt.scatter(first_medals['Normalized Participated Events'], first_medals['First Medal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b8bd2-f77d-4b9f-b4d5-f8176469187c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "b88bc78c-260f-4356-984b-1fc2ac72d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "00680921-4193-4888-9ca7-94ad5932ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = first_medals[['Team Size', 'Participated Events', 'Sex', 'Events Difference', 'Host Continent', 'Normalized Team Size', 'Normalized Participated Events']].to_numpy()\n",
    "y = first_medals[['First Medal']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "cb5a813f-1565-45f7-8f66-956bf2991f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01356068  0.02956255  0.19907306  0.00872622 -0.06181238  0.08532558\n",
      "   0.04914614  0.16274269]]\n",
      "0.7784090909090909\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "score = reg.score(X_test, y_test)\n",
    "print(reg.coef_)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "67bfd20f-ee67-4315-8a8b-980b37f50234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 42.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 106, number of negative: 302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 448\n",
      "[LightGBM] [Info] Number of data points in the train set: 408, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259804 -> initscore=-1.046988\n",
      "[LightGBM] [Info] Start training from score -1.046988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "BaggingClassifier                  0.78               0.65     0.65      0.75   \n",
       "RandomForestClassifier             0.78               0.65     0.65      0.75   \n",
       "LGBMClassifier                     0.72               0.63     0.63      0.71   \n",
       "LogisticRegression                 0.78               0.61     0.61      0.73   \n",
       "AdaBoostClassifier                 0.76               0.61     0.61      0.72   \n",
       "NearestCentroid                    0.68               0.61     0.61      0.68   \n",
       "Perceptron                         0.74               0.60     0.60      0.71   \n",
       "ExtraTreesClassifier               0.75               0.59     0.59      0.71   \n",
       "LinearSVC                          0.77               0.59     0.59      0.71   \n",
       "DecisionTreeClassifier             0.68               0.59     0.59      0.68   \n",
       "CalibratedClassifierCV             0.77               0.59     0.59      0.71   \n",
       "BernoulliNB                        0.69               0.59     0.59      0.68   \n",
       "PassiveAggressiveClassifier        0.73               0.58     0.58      0.70   \n",
       "LinearDiscriminantAnalysis         0.76               0.57     0.57      0.69   \n",
       "GaussianNB                         0.76               0.57     0.57      0.69   \n",
       "SGDClassifier                      0.68               0.57     0.57      0.67   \n",
       "LabelPropagation                   0.66               0.56     0.56      0.65   \n",
       "RidgeClassifier                    0.75               0.56     0.56      0.67   \n",
       "LabelSpreading                     0.65               0.55     0.55      0.65   \n",
       "KNeighborsClassifier               0.72               0.55     0.55      0.67   \n",
       "QuadraticDiscriminantAnalysis      0.75               0.55     0.55      0.67   \n",
       "RidgeClassifierCV                  0.75               0.55     0.55      0.67   \n",
       "NuSVC                              0.74               0.54     0.54      0.66   \n",
       "SVC                                0.73               0.54     0.54      0.66   \n",
       "ExtraTreeClassifier                0.62               0.52     0.52      0.62   \n",
       "DummyClassifier                    0.72               0.50     0.50      0.60   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "BaggingClassifier                    0.02  \n",
       "RandomForestClassifier               0.12  \n",
       "LGBMClassifier                       0.15  \n",
       "LogisticRegression                   0.01  \n",
       "AdaBoostClassifier                   0.08  \n",
       "NearestCentroid                      0.01  \n",
       "Perceptron                           0.02  \n",
       "ExtraTreesClassifier                 0.06  \n",
       "LinearSVC                            0.01  \n",
       "DecisionTreeClassifier               0.01  \n",
       "CalibratedClassifierCV               0.01  \n",
       "BernoulliNB                          0.00  \n",
       "PassiveAggressiveClassifier          0.01  \n",
       "LinearDiscriminantAnalysis           0.00  \n",
       "GaussianNB                           0.00  \n",
       "SGDClassifier                        0.01  \n",
       "LabelPropagation                     0.01  \n",
       "RidgeClassifier                      0.01  \n",
       "LabelSpreading                       0.01  \n",
       "KNeighborsClassifier                 0.01  \n",
       "QuadraticDiscriminantAnalysis        0.00  \n",
       "RidgeClassifierCV                    0.01  \n",
       "NuSVC                                0.01  \n",
       "SVC                                  0.01  \n",
       "ExtraTreeClassifier                  0.00  \n",
       "DummyClassifier                      0.00  "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139b732-f217-4523-bd8e-0bab73eb0917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
